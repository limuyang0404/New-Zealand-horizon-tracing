# -*- coding: utf-8 -*-
import torch
from torch import nn
import torch.nn.functional as F
import numpy as np
def conv_init(layer):
    nn.init.kaiming_normal_(layer.weight.data)
    if layer.bias is not None:
        layer.bias.data.zero_()
    return
class ResBlock(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(ResBlock, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=1, padding=0, stride=1)
        self.conv2 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=3, padding=1, stride=1)
        self.conv3 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, padding=0, stride=1)
        self.conv4 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, padding=0, stride=1)
        self.conv5 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, padding=1, stride=2)
        self.ReLU1 = nn.ReLU(inplace=True)
        self.ReLU2 = nn.ReLU(inplace=True)
        self.ReLU3 = nn.ReLU(inplace=True)
        self.ReLU4 = nn.ReLU(inplace=True)
        self.norm1 = nn.BatchNorm2d(in_channels)
        self.norm2 = nn.BatchNorm2d(in_channels)
        self.norm3 = nn.BatchNorm2d(out_channels)
        self.norm4 = nn.BatchNorm2d(out_channels)
        self.norm5 = nn.BatchNorm2d(out_channels)
        pass
    def forward(self, x):
        conv1 = self.conv1(x)
        conv1 = self.norm1(conv1)
        ReLU1 = self.ReLU1(conv1)
        conv2 = self.conv2(ReLU1)
        conv2 = self.norm2(conv2)
        ReLU2 = self.ReLU2(conv2)
        conv3 = self.conv3(ReLU2)
        conv3 = self.norm3(conv3)
        conv4 = self.conv4(x)
        conv4 = self.norm4(conv4)
        conv5 = self.ReLU3(conv4 + conv3)
        conv5 = self.conv5(conv5)
        conv5 = self.norm5(conv5)
        out = self.ReLU4(conv5)
        return out
    def initialize(self):
        conv_init(self.conv1)
        conv_init(self.conv2)
        conv_init(self.conv3)
        conv_init(self.conv4)
        conv_init(self.conv5)
class UpSample(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(UpSample, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=5, padding=2, stride=1)
        self.conv2 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1, stride=1)
        self.conv3 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=5, padding=2, stride=1)
        self.ReLU1 = nn.ReLU(inplace=True)
        self.ReLU2 = nn.ReLU(inplace=True)
        self.ReLU0 = nn.ReLU(inplace=True)
        self.norm1 = nn.BatchNorm2d(in_channels)
        self.norm2 = nn.BatchNorm2d(out_channels)
        self.norm3 = nn.BatchNorm2d(out_channels)
        pass
    def forward(self, x):
        x = self.ReLU0(x)
        conv1 = self.conv1(x)
        conv1 = self.norm1(conv1)
        ReLU1 = self.ReLU1(conv1)
        conv2 = self.conv2(ReLU1)
        conv2 = self.norm2(conv2)
        conv3 = self.conv3(x)
        conv3 = self.norm3(conv3)
        out = self.ReLU2(conv2 + conv3)
        return out
    def initialize(self):
        conv_init(self.conv1)
        conv_init(self.conv2)
        conv_init(self.conv3)
class ResNet(nn.Module):
    def __init__(self, n_classes=1):
        super(ResNet, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32,
                                   kernel_size=7, padding=3, stride=2)
        self.ReLU1 = nn.ReLU(inplace=True)
        self.block1 = ResBlock(32, 64)
        self.block2 = ResBlock(64, 128)
        self.block3 = ResBlock(128, 256)
        self.block4 = ResBlock(256, 512)
        self.conv2 = nn.Conv2d(in_channels=512, out_channels=512,
                                   kernel_size=1, padding=0, stride=1)
        self.ReLU2 = nn.ReLU(inplace=True)
        self.upsample1 = nn.Upsample(scale_factor=2, mode='nearest')
        self.unblock1 = UpSample(768, 256)
        self.upsample2 = nn.Upsample(scale_factor=2, mode='nearest')
        self.unblock2 = UpSample(384, 128)
        self.upsample3 = nn.Upsample(scale_factor=2, mode='nearest')
        self.unblock3 = UpSample(192, 64)
        self.upsample4 = nn.Upsample(scale_factor=2, mode='nearest')
        self.unblock4 = UpSample(96, 32)
        self.upsample5 = nn.Upsample(scale_factor=2, mode='nearest')
        self.unblock5 = UpSample(32, 32)
        self.conv3 = nn.Conv2d(in_channels=32, out_channels=32,
                                   kernel_size=1, padding=0, stride=1)
        self.ReLU3 = nn.ReLU(inplace=True)
        self.conv4 = nn.Conv2d(in_channels=32, out_channels=32,
                               kernel_size=1, padding=0, stride=1)
        self.ReLU4 = nn.ReLU(inplace=True)
        self.conv5 = nn.Conv2d(in_channels=32, out_channels=n_classes,
                               kernel_size=1, padding=0, stride=1)
        self.norm1 = nn.BatchNorm2d(32)
        self.norm2 = nn.BatchNorm2d(512)
        self.norm3 = nn.BatchNorm2d(32)
        self.norm4 = nn.BatchNorm2d(32)
        pass
    def ParameterInitialize(self):
        conv_init(self.conv1)
        self.block1.initialize()
        self.block2.initialize()
        self.block3.initialize()
        self.block4.initialize()
        conv_init(self.conv2)
        self.unblock1.initialize()
        self.unblock2.initialize()
        self.unblock3.initialize()
        self.unblock4.initialize()
        self.unblock5.initialize()
        conv_init(self.conv3)
        conv_init(self.conv4)
        conv_init(self.conv5)
        print('ALL convolutional layer have been initialized!')
    def forward(self, x):
        feature_1_1 = self.conv1(x)
        feature_1_1 = self.norm1(feature_1_1)
        feature_1_1 = self.ReLU1(feature_1_1)
        # print('1_1', feature_1_1.size())
        feature_1_2 = self.block1(feature_1_1)
        # print('1_2', feature_1_2.size())
        feature_1_3 = self.block2(feature_1_2)
        # print('1_3', feature_1_3.size())
        feature_1_4 = self.block3(feature_1_3)
        # print('1_4', feature_1_4.size())
        feature_1_5 = self.block4(feature_1_4)
        # print('1_5', feature_1_5.size())
        feature_2_1 = self.conv2(feature_1_5)
        feature_2_1 = self.norm2(feature_2_1)
        feature_2_1 = self.ReLU2(feature_2_1)
        feature_2_1 = self.upsample1(feature_2_1)
        cat1 = torch.cat((feature_2_1, feature_1_4), dim=1)
        feature_2_2 = self.unblock1(cat1)
        feature_2_2 = self.upsample2(feature_2_2)
        cat2 = torch.cat((feature_2_2, feature_1_3), dim=1)
        feature_2_3 = self.unblock2(cat2)
        feature_2_3 = self.upsample3(feature_2_3)
        cat3 = torch.cat((feature_2_3, feature_1_2), dim=1)
        feature_2_4 = self.unblock3(cat3)
        feature_2_4 = self.upsample4(feature_2_4)
        cat4 = torch.cat((feature_2_4, feature_1_1), dim=1)
        feature_2_5 = self.unblock4(cat4)
        feature_2_5 = self.upsample5(feature_2_5)
        feature_2_6 = self.unblock5(feature_2_5)
        feature_2_7 = self.conv3(feature_2_6)
        feature_2_7 = self.norm3(feature_2_7)
        feature_2_7 = self.ReLU3(feature_2_7)
        feature_2_8 = self.conv4(feature_2_7)
        feature_2_8 = self.norm4(feature_2_8)
        feature_2_8 = self.ReLU4(feature_2_8)
        output = self.conv5(feature_2_8)
        # print('check!')
        return output
class DoubleConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(DoubleConv, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1, stride=1)
        self.conv2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, padding=1, stride=2)
        self.ReLU1 = nn.ReLU(inplace=True)
        self.ReLU2 = nn.ReLU(inplace=True)
        self.norm1 = nn.BatchNorm2d(out_channels)
        self.norm2 = nn.BatchNorm2d(out_channels)
        pass
    def forward(self, x):
        feature1 = self.conv1(x)
        feature1 = self.norm1(feature1)
        feature1 = self.ReLU1(feature1)
        feature2 = self.conv2(feature1)
        feature2 = self.norm2(feature2)
        out = self.ReLU2(feature2)
        return out
    def initialize(self):
        conv_init(self.conv1)
        conv_init(self.conv2)
        pass
class InDoubleConv(nn.Module):
    def __init__(self, in_channels, out_channels, mode='nearest'):
        super(InDoubleConv, self).__init__()
        self.upsample = nn.Upsample(scale_factor=2, mode=mode)
        self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1, stride=1)
        self.conv2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, padding=1, stride=1)
        self.ReLU1 = nn.ReLU(inplace=True)
        self.ReLU2 = nn.ReLU(inplace=True)
        self.norm0 = nn.BatchNorm2d(in_channels)
        self.norm1 = nn.BatchNorm2d(out_channels)
        self.norm2 = nn.BatchNorm2d(out_channels)
        pass
    def forward(self, x):
        feature_upsample = self.upsample(x)
        feature_upsample = self.norm0(feature_upsample)
        feature1 = self.conv1(feature_upsample)
        feature1 = self.norm1(feature1)
        feature1 = self.ReLU1(feature1)
        feature2 = self.conv2(feature1)
        feature2 = self.norm2(feature2)
        feature2 = self.ReLU2(feature2)
        return  feature2
    def initialize(self):
        conv_init(self.conv1)
        conv_init(self.conv2)
        pass
# class AutoEncoder(nn.Module):
#     def __init__(self, in_channels=1, out_channels=1):
#         super(AutoEncoder, self).__init__()
#         self.conv1 = DoubleConv(in_channels=in_channels, out_channels=64)
#         self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)
#         self.conv2 = DoubleConv(in_channels=64, out_channels=128)
#         self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)
#         self.conv3 = DoubleConv(in_channels=128, out_channels=256)
#         self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)
#         self.conv4 = DoubleConv(in_channels=256, out_channels=512)
#         self.maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)
#         self.middle = DoubleConv(in_channels=512, out_channels=512)
#         self.maxunpool1 = nn.MaxUnpool2d(kernel_size=2, stride=2)
#         self.conv5 = DoubleConv(in_channels=512, out_channels=256)
#         self.maxunpool2 = nn.MaxUnpool2d(kernel_size=2, stride=2)
#         self.conv6 = DoubleConv(in_channels=256, out_channels=128)
#         self.maxunpool3 = nn.MaxUnpool2d(kernel_size=2, stride=2)
#         self.conv7 = DoubleConv(in_channels=128, out_channels=64)
#         self.maxunpool4 = nn.MaxUnpool2d(kernel_size=2, stride=2)
#         self.conv8 = DoubleConv(in_channels=64, out_channels=64)
#         self.conv9 = nn.Conv2d(in_channels=64, out_channels=out_channels, kernel_size=1, padding=0, stride=1)
#     def forward(self, x):
#         feature1 = self.conv1(x)
#         feature1, indices1 = self.maxpool1(feature1)
#         feature2 = self.conv2(feature1)
#         feature2, indices2 = self.maxpool2(feature2)
#         feature3 = self.conv3(feature2)
#         feature3, indices3 = self.maxpool3(feature3)
#         feature4 = self.conv4(feature3)
#         feature4, indices4 = self.maxpool4(feature4)
#         feature5 = self.middle(feature4)
#         feature5 = self.maxunpool1(feature5, indices4)
#         feature6 = self.conv5(feature5)
#         feature6 = self.maxunpool2(feature6, indices3)
#         feature7 = self.conv6(feature6)
#         feature7 = self.maxunpool3(feature7, indices2)
#         feature8 = self.conv7(feature7)
#         feature8 = self.maxunpool4(feature8, indices1)
#         feature9 = self.conv8(feature8)
#         feature10 = self.conv9(feature9)
#         return feature10
#     def ParameterInitialize(self):
#         self.conv1.initialize()
#         self.conv2.initialize()
#         self.conv3.initialize()
#         self.conv4.initialize()
#         self.conv5.initialize()
#         self.conv6.initialize()
#         self.conv7.initialize()
#         self.conv8.initialize()
#         conv_init(self.conv9)
#         self.middle.initialize()
#         print('All conv have been initialized!')
# class FreezeUnet(nn.Module):
#     def __init__(self, in_channels=1, out_channels=1):
#         super(FreezeUnet, self).__init__()
#         self.conv1 = DoubleConv(in_channels=in_channels, out_channels=64)
#         self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)
#         self.conv2 = DoubleConv(in_channels=64, out_channels=128)
#         self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)
#         self.conv3 = DoubleConv(in_channels=128, out_channels=256)
#         self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)
#         self.conv4 = DoubleConv(in_channels=256, out_channels=512)
#         self.maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)
#         self.middle = DoubleConv(in_channels=512, out_channels=512)
#         self.maxunpool1 = nn.MaxUnpool2d(kernel_size=2, stride=2)
#         self.conv5 = DoubleConv(in_channels=1024, out_channels=256)
#         self.maxunpool2 = nn.MaxUnpool2d(kernel_size=2, stride=2)
#         self.conv6 = DoubleConv(in_channels=512, out_channels=128)
#         self.maxunpool3 = nn.MaxUnpool2d(kernel_size=2, stride=2)
#         self.conv7 = DoubleConv(in_channels=256, out_channels=64)
#         self.maxunpool4 = nn.MaxUnpool2d(kernel_size=2, stride=2)
#         self.conv8 = DoubleConv(in_channels=128, out_channels=64)
#         self.conv9 = nn.Conv2d(in_channels=64, out_channels=out_channels, kernel_size=1, padding=0, stride=1)
#     def forward(self, x):
#         with torch.no_grad():
#             feature1 = self.conv1(x)
#             maxpool1, indices1 = self.maxpool1(feature1)
#             feature2 = self.conv2(maxpool1)
#             maxpool2, indices2 = self.maxpool2(feature2)
#             feature3 = self.conv3(maxpool2)
#             maxpool3, indices3 = self.maxpool3(feature3)
#             feature4 = self.conv4(maxpool3)
#             maxpool4, indices4 = self.maxpool4(feature4)
#         feature5 = self.middle(maxpool4)
#         feature5 = self.maxunpool1(feature5, indices4)
#         temp1 = torch.cat((feature5, feature4), dim=1)
#         feature6 = self.conv5(temp1)
#         feature6 = self.maxunpool2(feature6, indices3)
#         temp2 = torch.cat((feature6, feature3), dim=1)
#         feature7 = self.conv6(temp2)
#         feature7 = self.maxunpool3(feature7, indices2)
#         temp3 = torch.cat((feature7, feature2), dim=1)
#         feature8 = self.conv7(temp3)
#         feature8 = self.maxunpool4(feature8, indices1)
#         temp4 = torch.cat((feature8, feature1), dim=1)
#         feature9 = self.conv8(temp4)
#         feature10 = self.conv9(feature9)
#         return feature10
#     def ParameterInitialize(self):
#         self.conv1.initialize()
#         self.conv2.initialize()
#         self.conv3.initialize()
#         self.conv4.initialize()
#         self.conv5.initialize()
#         self.conv6.initialize()
#         self.conv7.initialize()
#         self.conv8.initialize()
#         conv_init(self.conv9)
#         self.middle.initialize()
#         print('All conv have been initialized!')
class AutoEncoder(nn.Module):
    def __init__(self, in_channels=1, out_channels=1):
        super(AutoEncoder, self).__init__()
        # self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=64,
        #                        kernel_size=7, padding=3, stride=2)
        self.conv1 = DoubleConv(in_channels=in_channels, out_channels=64)
        # self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.conv2 = DoubleConv(in_channels=64, out_channels=128)
        # self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)
        # self.conv3 = DoubleConv(in_channels=128, out_channels=256)
        # self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)
        self.middle = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=1, padding=0, stride=1)
        self.conv4 = InDoubleConv(in_channels=256, out_channels=128, mode='nearest')
        # self.maxunpool1 = nn.Upsample(scale_factor=2, mode='nearest')
        # self.conv4 = DoubleConv(in_channels=256, out_channels=128)
        # self.maxunpool2 = nn.Upsample(scale_factor=2, mode='nearest')
        self.conv5 = InDoubleConv(in_channels=128, out_channels=64, mode='nearest')
        # self.conv5 = DoubleConv(in_channels=128, out_channels=64)
        # self.maxunpool3 = nn.Upsample(scale_factor=2, mode='nearest')
        # self.conv6 = DoubleConv(in_channels=128, out_channels=64)
        self.conv6 = nn.Conv2d(in_channels=64, out_channels=out_channels, kernel_size=1, padding=0, stride=1)
        self.batchnorm1 = nn.BatchNorm2d(256)
        # self.ReLU1 = nn.ReLU(inplace=True)
    def forward(self, x):
        feature1 = self.conv1(x)
        feature2 = self.conv2(feature1)
        feature_middle = self.middle(feature2)
        feature_middle = self.batchnorm1(feature_middle)
        # print('middle size:', feature_middle.size())
        feature4 = self.conv4(feature_middle)
        # print('feature4 size:', feature4.size())
        feature5 = self.conv5(feature4)
        feature6 = self.conv6(feature5)
        # feature1 = self.conv1(x)
        # feature1 = self.maxpool1(feature1)
        # feature2 = self.conv2(feature1)
        # feature2 = self.maxpool2(feature2)
        # # feature3 = self.conv3(feature2)
        # # feature3 = self.maxpool3(feature3)
        # feature4 = self.middle(feature2)
        # feature4 = self.batchnorm1(feature4)
        # feature4 = self.ReLU1(feature4)
        # feature5 = self.maxunpool1(feature4)
        # feature5 = self.conv4(feature5)
        # feature6 = self.maxunpool2(feature5)
        # feature6 = self.conv5(feature6)
        # # feature7 = self.maxunpool3(feature6)
        # # feature7 = self.conv6(feature7)
        # feature8 = self.conv7(feature6)
        return feature6
    def ParameterInitialize(self):
        # conv_init(self.conv1)
        self.conv1.initialize()
        self.conv2.initialize()
        # self.conv3.initialize()
        self.conv4.initialize()
        self.conv5.initialize()
        # self.conv6.initialize()
        conv_init(self.conv6)
        conv_init(self.middle)
        print('All conv have been initialized!')
        pass

# class AutoEncoder(nn.Module):
#     def __init__(self, in_channels=1, out_channels=1):
#         super(AutoEncoder, self).__init__()
#         self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=32,
#                                kernel_size=7, padding=3, stride=2)
#         self.ReLU1 = nn.ReLU(inplace=True)
#         self.block1 = ResBlock(32, 64)
#         self.block2 = ResBlock(64, 128)
#         self.block3 = ResBlock(128, 256)
#         self.block4 = ResBlock(256, 512)
#         self.conv2 = nn.Conv2d(in_channels=512, out_channels=512,
#                                kernel_size=1, padding=0, stride=1)
#         self.ReLU2 = nn.ReLU(inplace=True)
#         self.upsample1 = nn.Upsample(scale_factor=2, mode='nearest')
#         self.unblock1 = UpSample(512, 256)
#         self.upsample2 = nn.Upsample(scale_factor=2, mode='nearest')
#         self.unblock2 = UpSample(256, 128)
#         self.upsample3 = nn.Upsample(scale_factor=2, mode='nearest')
#         self.unblock3 = UpSample(128, 64)
#         self.upsample4 = nn.Upsample(scale_factor=2, mode='nearest')
#         self.unblock4 = UpSample(64, 32)
#         self.upsample5 = nn.Upsample(scale_factor=2, mode='nearest')
#         self.unblock5 = UpSample(32, 32)
#         self.conv3 = nn.Conv2d(in_channels=32, out_channels=32,
#                                kernel_size=1, padding=0, stride=1)
#         self.ReLU3 = nn.ReLU(inplace=True)
#         self.conv4 = nn.Conv2d(in_channels=32, out_channels=32,
#                                kernel_size=1, padding=0, stride=1)
#         self.ReLU4 = nn.ReLU(inplace=True)
#         self.conv5 = nn.Conv2d(in_channels=32, out_channels=out_channels,
#                                kernel_size=1, padding=0, stride=1)
#         self.norm1 = nn.BatchNorm2d(32)
#         self.norm2 = nn.BatchNorm2d(512)
#         self.norm3 = nn.BatchNorm2d(32)
#         self.norm4 = nn.BatchNorm2d(32)
#         pass
#     def ParameterInitialize(self):
#         conv_init(self.conv1)
#         self.block1.initialize()
#         self.block2.initialize()
#         self.block3.initialize()
#         self.block4.initialize()
#         conv_init(self.conv2)
#         self.unblock1.initialize()
#         self.unblock2.initialize()
#         self.unblock3.initialize()
#         self.unblock4.initialize()
#         self.unblock5.initialize()
#         conv_init(self.conv3)
#         conv_init(self.conv4)
#         conv_init(self.conv5)
#         print('ALL convolutional layer have been initialized!')
#
#     def forward(self, x):
#         feature_1_1 = self.conv1(x)
#         feature_1_1 = self.norm1(feature_1_1)
#         feature_1_1 = self.ReLU1(feature_1_1)
#         # print('1_1', feature_1_1.size())
#         feature_1_2 = self.block1(feature_1_1)
#         # print('1_2', feature_1_2.size())
#         feature_1_3 = self.block2(feature_1_2)
#         # print('1_3', feature_1_3.size())
#         feature_1_4 = self.block3(feature_1_3)
#         # print('1_4', feature_1_4.size())
#         feature_1_5 = self.block4(feature_1_4)
#         # print('1_5', feature_1_5.size())
#         feature_2_1 = self.conv2(feature_1_5)
#         feature_2_1 = self.norm2(feature_2_1)
#         feature_2_1 = self.ReLU2(feature_2_1)
#         feature_2_1 = self.upsample1(feature_2_1)
#         # cat1 = torch.cat((feature_2_1, feature_1_4), dim=1)
#         feature_2_2 = self.unblock1(feature_2_1)
#         feature_2_2 = self.upsample2(feature_2_2)
#         # cat2 = torch.cat((feature_2_2, feature_1_3), dim=1)
#         feature_2_3 = self.unblock2(feature_2_2)
#         feature_2_3 = self.upsample3(feature_2_3)
#         # cat3 = torch.cat((feature_2_3, feature_1_2), dim=1)
#         feature_2_4 = self.unblock3(feature_2_3)
#         feature_2_4 = self.upsample4(feature_2_4)
#         # cat4 = torch.cat((feature_2_4, feature_1_1), dim=1)
#         feature_2_5 = self.unblock4(feature_2_4)
#         feature_2_5 = self.upsample5(feature_2_5)
#         feature_2_6 = self.unblock5(feature_2_5)
#         feature_2_7 = self.conv3(feature_2_6)
#         feature_2_7 = self.norm3(feature_2_7)
#         feature_2_7 = self.ReLU3(feature_2_7)
#         feature_2_8 = self.conv4(feature_2_7)
#         feature_2_8 = self.norm4(feature_2_8)
#         feature_2_8 = self.ReLU4(feature_2_8)
#         output = self.conv5(feature_2_8)
#         # print('check!')
#         return output

class FreezeUnet(nn.Module):
    def __init__(self, in_channels=1, out_channels=1):
        super(FreezeUnet, self).__init__()
        self.conv1 = DoubleConv(in_channels=in_channels, out_channels=64)
        self.conv2 = DoubleConv(in_channels=64, out_channels=128)
        # self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1, stride=1)
        self.conv3 = ResBlock(in_channels=128, out_channels=256)
        self.conv4 = ResBlock(in_channels=256, out_channels=512)
        # self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)
        # self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1, stride=1)
        # self.batchnorm4 = nn.BatchNorm2d(128)
        # self.ReLU4 = nn.ReLU(inplace=True)
        # self.conv4 = DoubleConv(in_channels=256, out_channels=512)
        # self.maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)
        # self.middle = DoubleConv(in_channels=512, out_channels=512)
        self.middle = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=1, padding=0, stride=1)
        self.batchnorm5 = nn.BatchNorm2d(512)
        # self.ReLU5 = nn.ReLU(inplace=True)
        # self.middle2 = nn.Conv2d(in_channels=512, out_channels=64, kernel_size=1, padding=0, stride=1)
        # self.middle3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=1, padding=0, stride=1)
        self.maxunpool1 = nn.Upsample(scale_factor=2, mode='nearest')#mode = 'bilinear'?
        # self.conv5 = nn.Conv2d(in_channels=384, out_channels=128, kernel_size=3, padding=1, stride=1)
        self.conv5 = UpSample(in_channels=512, out_channels=256)
        self.maxunpool2 = nn.Upsample(scale_factor=2, mode='nearest')
        self.conv6 = UpSample(in_channels=512, out_channels=128)
        self.maxunpool3 = nn.Upsample(scale_factor=2, mode='nearest')
        self.conv7 = UpSample(in_channels=256, out_channels=64)
        # self.maxunpool4 = nn.MaxUnpool2d(kernel_size=2, stride=2)
        # self.conv8 = DoubleConv(in_channels=128, out_channels=64)
        self.maxunpool4 = nn.Upsample(scale_factor=2, mode='nearest')
        self.conv8 = UpSample(in_channels=128, out_channels=64)
        # self.batchnorm9 = nn.BatchNorm2d(64)
        # self.ReLU9 = nn.ReLU(inplace=True)
        self.conv9 = nn.Conv2d(in_channels=65, out_channels=64, kernel_size=3, padding=1, stride=1)
        self.batchnorm9 = nn.BatchNorm2d(64)
        self.ReLU9 = nn.ReLU(inplace=True)
        self.conv10 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1, stride=1)
        self.batchnorm10 = nn.BatchNorm2d(64)
        self.ReLU10 = nn.ReLU(inplace=True)
        self.conv11 = nn.Conv2d(in_channels=64, out_channels=out_channels, kernel_size=3, padding=1, stride=1)

        # self.conv12 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=1, padding=0, stride=1)
        # self.conv13 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=1, padding=0, stride=1)
        # self.conv14 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=1, padding=0, stride=1)
        # self.conv15 = nn.Conv2d(in_channels=in_channels, out_channels=1, kernel_size=1, padding=0, stride=1)
        # self.batchnorm12 = nn.BatchNorm2d(256)
        # self.batchnorm13 = nn.BatchNorm2d(128)
        # self.batchnorm14 = nn.BatchNorm2d(64)
        # self.batchnorm15 = nn.BatchNorm2d(1)
    def forward(self, x):
        with torch.no_grad():
            feature1 = self.conv1(x)
        feature2 = self.conv2(feature1)
        feature3 = self.conv3(feature2)
        feature4 = self.conv4(feature3)
        # maxpool3 = self.maxpool3(feature3)
        # feature4 = self.conv4(maxpool3)
        # maxpool4, indices4 = self.maxpool4(feature4)
        # feature5 = self.middle1(feature4)
        # feature6 = self.middle2(feature5)
        # feature7 = self.middle3(feature6)
        feature_middle = self.middle(feature4)
        feature_middle = self.batchnorm5(feature_middle)
        # feature_middle = self.ReLU5(feature_middle)
        # feature5 = self.maxunpool1(feature5, indices4)
        # temp1 = torch.cat((feature7, feature4), dim=1)
        unpool1 = self.maxunpool1(feature_middle)
        feature5 = self.conv5(unpool1)
        # skip1 = self.conv12(feature3)
        # skip1 = self.batchnorm12(skip1)
        # temp1 = skip1 + feature5
        temp1 = torch.cat((feature3, feature5), dim=1)
        # feature5 = self.conv5(temp1)
        # feature6 = self.maxunpool2(feature6)
        # temp2 = torch.cat((feature6, feature3), dim=1)
        unpool2 = self.maxunpool2(temp1)
        feature6 = self.conv6(unpool2)
        # skip2 = self.conv13(feature2)
        # skip2 = self.batchnorm13(skip2)
        temp2 = torch.cat((feature2, feature6), dim=1)
        # feature6 = self.conv6(temp2)
        # temp2 = skip2 + feature6
        # feature7 = self.maxunpool3(feature7, indices2)
        # temp3 = torch.cat((feature7, feature2), dim=1)
        unpool3 = self.maxunpool3(temp2)
        feature7 = self.conv7(unpool3)
        # skip3 = self.conv14(feature1)
        # skip3 = self.batchnorm14(skip3)
        temp3 = torch.cat((feature1, feature7), dim=1)
        # feature7 = self.conv7(temp3)
        # temp3 = skip3 + feature7
        unpool4 = self.maxunpool4(temp3)
        feature8 = self.conv8(unpool4)
        # skip4 = self.conv15(x)
        # skip4 = self.batchnorm15(skip4)
        temp4 = torch.cat((x, feature8), dim=1)
        # feature8 = self.conv8(temp4)
        # temp4 = skip4 + feature8
        # feature8 = self.maxunpool4(feature8, indices1)
        # temp4 = torch.cat((feature8, feature1), dim=1)
        # feature9 = self.conv9(feature8)
        # feature9 = self.batchnorm9(feature9)
        # feature9 = self.ReLU9(feature9)
        feature9 = self.conv9(temp4)
        feature9 = self.batchnorm9(feature9)
        feature9 = self.ReLU9(feature9)
        feature10 = self.conv10(feature9)
        feature10 = self.batchnorm10(feature10)
        feature10 = self.ReLU10(feature10)
        # feature10 = self.conv9(feature9)
        feature11 = self.conv11(feature10)
        return feature11
    def ParameterInitialize(self):
        self.conv1.initialize()
        self.conv2.initialize()
        self.conv3.initialize()
        self.conv4.initialize()
        # conv_init(self.conv3)
        # conv_init(self.conv4)
        self.conv5.initialize()
        # conv_init(self.conv5)
        self.conv6.initialize()
        self.conv7.initialize()
        # self.conv8.initialize()
        # conv_init(self.conv9)
        self.conv8.initialize()
        conv_init(self.conv9)
        # self.middle.initialize()
        conv_init(self.middle)
        conv_init(self.conv10)
        conv_init(self.conv11)
        # conv_init(self.conv12)
        # conv_init(self.conv13)
        # conv_init(self.conv14)
        # conv_init(self.conv15)
        # conv_init(self.middle2)
        # conv_init(self.middle3)
        print('All conv have been initialized!')
# class FreezeUnet(nn.Module):
#     def __init__(self, in_channels=1, out_channels=1):
#         super(FreezeUnet, self).__init__()
#         # self.conv1 = nn.Conv2d(in_channels=in_channels, out_channels=64,
#         #                            kernel_size=7, padding=3, stride=2)
#         # self.ReLU1 = nn.ReLU(inplace=True)
#         self.conv1 = DoubleConv(in_channels=in_channels, out_channels=64)
#         self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)
#         self.conv2 = DoubleConv(in_channels=64, out_channels=64)
#         self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)
#         self.block1 = ResBlock(64, 128)
#         self.block2 = ResBlock(128, 256)
#         self.block3 = ResBlock(256, 512)
#         self.conv3 = nn.Conv2d(in_channels=512, out_channels=512,
#                                    kernel_size=1, padding=0, stride=1)
#         self.ReLU2 = nn.ReLU(inplace=True)
#         self.upsample1 = nn.Upsample(scale_factor=2, mode='nearest')
#         self.unblock1 = UpSample(768, 256)
#         self.upsample2 = nn.Upsample(scale_factor=2, mode='nearest')
#         self.unblock2 = UpSample(384, 128)
#         self.upsample3 = nn.Upsample(scale_factor=2, mode='nearest')
#         self.unblock3 = UpSample(192, 64)
#         self.upsample4 = nn.Upsample(scale_factor=2, mode='nearest')
#         self.unblock4 = UpSample(128, 32)
#         self.upsample5 = nn.Upsample(scale_factor=2, mode='nearest')
#         self.unblock5 = UpSample(32, 32)
#         self.conv4 = nn.Conv2d(in_channels=32, out_channels=32,
#                                    kernel_size=1, padding=0, stride=1)
#         self.ReLU3 = nn.ReLU(inplace=True)
#         self.conv5 = nn.Conv2d(in_channels=32, out_channels=32,
#                                kernel_size=1, padding=0, stride=1)
#         self.ReLU4 = nn.ReLU(inplace=True)
#         self.conv6 = nn.Conv2d(in_channels=32, out_channels=out_channels,
#                                kernel_size=1, padding=0, stride=1)
#         # self.norm1 = nn.BatchNorm2d(64)
#         self.norm2 = nn.BatchNorm2d(512)
#         self.norm3 = nn.BatchNorm2d(32)
#         self.norm4 = nn.BatchNorm2d(32)
#         pass
#     def ParameterInitialize(self):
#         # conv_init(self.conv1)
#         self.conv1.initialize()
#         self.block1.initialize()
#         self.block2.initialize()
#         self.block3.initialize()
#         # self.block4.initialize()
#         conv_init(self.conv3)
#         self.unblock1.initialize()
#         self.unblock2.initialize()
#         self.unblock3.initialize()
#         self.unblock4.initialize()
#         self.unblock5.initialize()
#         conv_init(self.conv4)
#         conv_init(self.conv5)
#         print('ALL convolutional layer have been initialized!')
#     def forward(self, x):
#         with torch.no_grad():
#             feature_1_1 = self.conv1(x)
#             feature_1_1_pool = self.maxpool1(feature_1_1)
#             feature_1_2 = self.conv2(feature_1_1_pool)
#             feature_1_2_pool = self.maxpool2(feature_1_2)
#         feature_1_3 = self.block1(feature_1_2_pool)
#         # print('1_3', feature_1_3.size())
#         feature_1_4 = self.block2(feature_1_3)
#         # print('1_4', feature_1_4.size())
#         feature_1_5 = self.block3(feature_1_4)
#         # print('1_5', feature_1_5.size())
#         feature_2_1 = self.conv3(feature_1_5)
#         feature_2_1 = self.norm2(feature_2_1)
#         feature_2_1 = self.ReLU2(feature_2_1)
#         feature_2_1_upsample = self.upsample1(feature_2_1)
#         cat1 = torch.cat((feature_2_1_upsample, feature_1_4), dim=1)
#         feature_2_2 = self.unblock1(cat1)
#         feature_2_2 = self.upsample2(feature_2_2)
#         cat2 = torch.cat((feature_2_2, feature_1_3), dim=1)
#         feature_2_3 = self.unblock2(cat2)
#         feature_2_3 = self.upsample3(feature_2_3)
#         cat3 = torch.cat((feature_2_3, feature_1_2), dim=1)
#         feature_2_4 = self.unblock3(cat3)
#         feature_2_4 = self.upsample4(feature_2_4)
#         cat4 = torch.cat((feature_2_4, feature_1_1), dim=1)
#         feature_2_5 = self.unblock4(cat4)
#         feature_2_5 = self.upsample5(feature_2_5)
#         feature_2_6 = self.unblock5(feature_2_5)
#         feature_2_7 = self.conv3(feature_2_6)
#         feature_2_7 = self.norm3(feature_2_7)
#         feature_2_7 = self.ReLU3(feature_2_7)
#         feature_2_8 = self.conv4(feature_2_7)
#         feature_2_8 = self.norm4(feature_2_8)
#         feature_2_8 = self.ReLU4(feature_2_8)
#         output = self.conv5(feature_2_8)
#         # print('check!')
#         return output
if __name__ == "__main__":
    print('hello')
    x1 = torch.rand(size=(1, 1, 128, 128))
    # net = ResBlock(8, 2)
    # net = AutoEncoder(1, 1)
    net = FreezeUnet(1, 1)
    # net.initialize()
    # net.ParameterInitialize()
    total_params = sum(p.numel() for p in net.parameters())
    print('parameter number:\n', total_params)
    # print('net dir:\n', dir(net))
    # print('The net:', net)
    # print('*'*60)
    # print('The state_dict:', net.state_dict())
    net.train()
    # a = nn.Upsample(scale_factor=2, mode='nearest')
    # b = a(x1)
    output = net(x1)
    print(type(output))
    print(output.size())
    # input = torch.tensor([[[[1., 2, 3, 4],
    #                         [5, 6, 7, 8],
    #                         [9, 10, 11, 12],
    #                         [13, 14, 15, 16]]]])
    # pool = nn.MaxPool2d(2, stride=2)
    # a= pool(input)
    # print(a)
    # d = np.array(np.arange(16, 0, -1)).reshape((1, 1, 4, 4))
    # c = torch.tensor(d)
    # print(c, type(c))
    # unpool = nn.Upsample(scale_factor=2, mode='nearest')
    # b = unpool(a)
    # print(b)

